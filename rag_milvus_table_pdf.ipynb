{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78872e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymilvus import (connections, MilvusClient, utility)\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef164e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#/var/tmp/.env\n",
    "load_dotenv()  # Loads from .env file by default\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "debug = os.getenv(\"DEBUG\")\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MILVUS_USER=os.getenv(\"MILVUS_USERNAME\")\n",
    "MILVUS_PASSWORD = os.getenv(\"MILVUS_PASSWORD\")\n",
    "MILVUS_URI = os.getenv(\"MILVUS_URI\")\n",
    "MILVUS_API_TOKEN = os.getenv(\"MILVUS_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b79abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "����������� �������� �������\n",
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two: Learning to Make Data Tables\n",
      "..............................................................................................\n",
      "Sample Data for Data Tables\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and\n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here\n",
      "are the results.\n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\n",
      "Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\n",
      "repeating this experiment include using safety goggles or safety spectacles and avoiding\n",
      "short circuits.\n",
      "Number of Coils Number of Paperclips\n",
      "5 3, 5, 4\n",
      "10 7, 8, 6\n",
      "15 11, 10, 12\n",
      "20 15, 13, 14\n",
      "Example 3: pH of Substances (GR 5–10)\n",
      "The following are pH values of common household substances taken by three different\n",
      "teams using pH probes. Safety precautions in repeating this experiment include hooded\n",
      "ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\n",
      "ammonia, or strong acids with children.\n",
      "Lemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\n",
      "Orange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\n",
      "Tomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\n",
      "10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\n",
      "12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\n",
      "Lye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\n",
      "10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\n",
      "Cola 3.0, 2.5, 3.2\n",
      "Teaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\n",
      "with the data as given and one with the pH scale 0 to 14 with the substances’ average\n",
      "pH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\n",
      "the upper end) or create a pH graphic organizer.\n",
      "1\n",
      "Example 4: Automobile Land Speed Records (GR 5-10)\n",
      "In the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\n",
      "Paris, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\n",
      "(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\n",
      "frozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\n",
      "Eagle is trying to break a land speed record of 800 mph. The Federation International de\n",
      "L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from\n",
      "http://www.landspeed.com/lsrinfo.asp.)\n",
      "Speed (mph) Driver Car Engine Date\n",
      "407.447 Craig Breedlove Spirit of America GE J47 8/5/63\n",
      "413.199 Tom Green Wingfoot Express WE J46 10/2/64\n",
      "434.22 Art Arfons Green Monster GE J79 10/5/64\n",
      "468.719 Craig Breedlove Spirit of America GE J79 10/13/64\n",
      "526.277 Craig Breedlove Spirit of America GE J79 10/15/65\n",
      "536.712 Art Arfons Green Monster GE J79 10/27/65\n",
      "555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\n",
      "576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)\n",
      "The following data were collected using a car with a water clock set to release a drop in\n",
      "a unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\n",
      "run. Create a data table with an average distance column and an average velocity column,\n",
      "create an average distance-time graph, and draw the best-fit line or curve. Estimate the\n",
      "car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\n",
      "it going at a constant speed, accelerating, or decelerating? How do you know?\n",
      "Time (drops of water) Distance (cm)\n",
      "1 10,11,9\n",
      "2 29, 31, 30\n",
      "3 59, 58, 61\n",
      "4 102, 100, 98\n",
      "5 122, 125, 127\n",
      "© 2006 WGBH Educational Foundation. All rights reserved.\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "# Removed direct import: from langchain_community.retrievers import MMRRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from pymilvus import connections, utility\n",
    "from docx import Document\n",
    "import os\n",
    "import pdfplumber # Import pdfplumber\n",
    "\n",
    "# --- Step 1: Load & Chunk Text ---\n",
    "pdf_path = r\"C:\\Gajanan\\data\\ast_sci_data_tables_sample.pdf\"\n",
    "full_text = \"\"\n",
    "try:\n",
    "    # Use pdfplumber to extract text from the PDF\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text from each page and append to full_text\n",
    "            page_text = page.extract_text()\n",
    "            if page_text: # Ensure text was extracted from the page\n",
    "                full_text += page_text + \"\\n\" # Add a newline between pages\n",
    "    if not full_text.strip(): # Check if any text was actually extracted\n",
    "         print(\"Warning: No text extracted from the PDF. Check if the PDF contains extractable text.\")\n",
    "         full_text = \"Placeholder text as no text could be extracted from the PDF.\" # Use placeholder if extraction fails\n",
    "    print(full_text)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: PDF file not found at the specified path: {pdf_path}\")\n",
    "    full_text = \"Placeholder text because the PDF file was not found. Please replace with actual PDF content extraction.\"\n",
    "except Exception as e:\n",
    "    print(f\"Error processing PDF file {pdf_path}: {e}\")\n",
    "    full_text = \"Placeholder text due to an error during PDF processing.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf018328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591891\n"
     ]
    }
   ],
   "source": [
    "print(len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31af2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eded7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_text_and_tables(pdf_path, lang='eng', dpi=300, verbose=True):\n",
    "    \"\"\"\n",
    "    Extracts text and tables from a PDF file.\n",
    "    Uses pdfplumber for digital PDFs, falls back to OCR if no text on page.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to PDF file.\n",
    "        lang (str): Language(s) for pytesseract OCR.\n",
    "        dpi (int): Resolution for OCR rendering.\n",
    "        verbose (bool): Print progress info.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            page_number (int): {\n",
    "                'text': extracted text (str),\n",
    "                'tables': list of tables (list of list of rows)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as plumber_pdf:\n",
    "        for i in range(len(doc)):\n",
    "            if verbose:\n",
    "                print(f\"Processing page {i+1}/{len(doc)}...\")\n",
    "\n",
    "            page_data = {'text': '', 'tables': []}\n",
    "\n",
    "            # Try extracting text + tables using pdfplumber\n",
    "            plumber_page = plumber_pdf.pages[i]\n",
    "            text = plumber_page.extract_text()\n",
    "            tables = plumber_page.extract_tables()\n",
    "\n",
    "            if text:\n",
    "                page_data['text'] = text\n",
    "                page_data['tables'] = tables or []\n",
    "            else:\n",
    "                # Fallback to OCR\n",
    "                page = doc.load_page(i)\n",
    "                pix = page.get_pixmap(dpi=dpi)\n",
    "                img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "                ocr_text = pytesseract.image_to_string(img, lang=lang)\n",
    "                page_data['text'] = ocr_text\n",
    "                page_data['tables'] = []  # OCR table extraction not handled here\n",
    "\n",
    "            results[i+1] = page_data\n",
    "\n",
    "    doc.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aee6789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1/2...\n",
      "Processing page 2/2...\n",
      "data dict_keys([1, 2])\n",
      "\n",
      "--- Page 1 ---\n",
      "Text:\n",
      "NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "����������� �������� �������\n",
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two: Learning to Make Data Tables\n",
      "..............................................................................................\n",
      "Sample Data for Data Tables\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and\n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here\n",
      "are the results.\n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\n",
      "Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\n",
      "repeating this experiment include using safety goggles or safety spectacles and avoiding\n",
      "short circuits.\n",
      "Number of Coils Number of Paperclips\n",
      "5 3, 5, 4\n",
      "10 7, 8, 6\n",
      "15 11, 10, 12\n",
      "20 15, 13, 14\n",
      "Example 3: pH of Substances (GR 5–10)\n",
      "The following are pH values of common household substances taken by three different\n",
      "teams using pH probes. Safety precautions in repeating this experiment include hooded\n",
      "ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\n",
      "ammonia, or strong acids with children.\n",
      "Lemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\n",
      "Orange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\n",
      "Tomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\n",
      "10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\n",
      "12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\n",
      "Lye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\n",
      "10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\n",
      "Cola 3.0, 2.5, 3.2\n",
      "Teaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\n",
      "with the data as given and one with the pH scale 0 to 14 with the substances’ average\n",
      "pH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\n",
      "the upper end) or create a pH graphic organizer.\n",
      "1\n",
      "Tables:\n",
      "['Number of Coils', 'Number of Paperclips']\n",
      "['5', '3, 5, 4']\n",
      "['10', '7, 8, 6']\n",
      "['15', '11, 10, 12']\n",
      "['20', '15, 13, 14']\n",
      "\n",
      "\n",
      "--- Page 2 ---\n",
      "Text:\n",
      "Example 4: Automobile Land Speed Records (GR 5-10)\n",
      "In the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\n",
      "Paris, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\n",
      "(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\n",
      "frozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\n",
      "Eagle is trying to break a land speed record of 800 mph. The Federation International de\n",
      "L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from\n",
      "http://www.landspeed.com/lsrinfo.asp.)\n",
      "Speed (mph) Driver Car Engine Date\n",
      "407.447 Craig Breedlove Spirit of America GE J47 8/5/63\n",
      "413.199 Tom Green Wingfoot Express WE J46 10/2/64\n",
      "434.22 Art Arfons Green Monster GE J79 10/5/64\n",
      "468.719 Craig Breedlove Spirit of America GE J79 10/13/64\n",
      "526.277 Craig Breedlove Spirit of America GE J79 10/15/65\n",
      "536.712 Art Arfons Green Monster GE J79 10/27/65\n",
      "555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\n",
      "576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)\n",
      "The following data were collected using a car with a water clock set to release a drop in\n",
      "a unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\n",
      "run. Create a data table with an average distance column and an average velocity column,\n",
      "create an average distance-time graph, and draw the best-fit line or curve. Estimate the\n",
      "car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\n",
      "it going at a constant speed, accelerating, or decelerating? How do you know?\n",
      "Time (drops of water) Distance (cm)\n",
      "1 10,11,9\n",
      "2 29, 31, 30\n",
      "3 59, 58, 61\n",
      "4 102, 100, 98\n",
      "5 122, 125, 127\n",
      "© 2006 WGBH Educational Foundation. All rights reserved.\n",
      "2\n",
      "Tables:\n",
      "['Speed (mph)', 'Driver', 'Car', 'Engine Date', None]\n",
      "['407.447', 'Craig Breedlove', 'Spirit of America', 'GE J47', '8/5/63']\n",
      "['413.199', 'Tom Green', 'Wingfoot Express', 'WE J46', '10/2/64']\n",
      "['434.22', 'Art Arfons', 'Green Monster', 'GE J79', '10/5/64']\n",
      "['468.719', 'Craig Breedlove', 'Spirit of America', 'GE J79', '10/13/64']\n",
      "['526.277', 'Craig Breedlove', 'Spirit of America', 'GE J79', '10/15/65']\n",
      "['536.712', 'Art Arfons', 'Green Monster', 'GE J79', '10/27/65']\n",
      "['555.127', 'Craig Breedlove', 'Spirit of America, Sonic 1', 'GE J79', '11/2/65']\n",
      "['576.553', 'Art Arfons', 'Green Monster', 'GE J79', '11/7/65']\n",
      "['600.601', 'Craig Breedlove', 'Spirit of America, Sonic 1', 'GE J79', '11/15/65']\n",
      "['622.407', 'Gary Gabelich', 'Blue Flame', 'Rocket', '10/23/70']\n",
      "['633.468', 'Richard Noble', 'Thrust 2', 'RR RG 146', '10/4/83']\n",
      "['763.035', 'Andy Green', 'Thrust SSC', 'RR Spey', '10/15/97']\n",
      "\n",
      "['Time (drops of water)', 'Distance (cm)']\n",
      "['1', '10,11,9']\n",
      "['2', '29, 31, 30']\n",
      "['3', '59, 58, 61']\n",
      "['4', '102, 100, 98']\n",
      "['5', '122, 125, 127']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_file = r\"C:\\Gajanan\\data\\ast_sci_data_tables_sample.pdf\"\n",
    "data = extract_text_and_tables(pdf_file, lang='eng', dpi=300)\n",
    "for page_num, content in data.items():\n",
    "    print(f\"\\n--- Page {page_num} ---\")\n",
    "    print(\"Text:\")\n",
    "    print(content['text'])\n",
    "    if content['tables']:\n",
    "        print(\"Tables:\")\n",
    "        for table in content['tables']:\n",
    "            for row in table:\n",
    "                print(row)\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No tables found on this page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12255f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'text': 'NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1',\n",
       "  'tables': [[['Number of Coils', 'Number of Paperclips'],\n",
       "    ['5', '3, 5, 4'],\n",
       "    ['10', '7, 8, 6'],\n",
       "    ['15', '11, 10, 12'],\n",
       "    ['20', '15, 13, 14']]]},\n",
       " 2: {'text': 'Example 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2',\n",
       "  'tables': [[['Speed (mph)', 'Driver', 'Car', 'Engine Date', None],\n",
       "    ['407.447', 'Craig Breedlove', 'Spirit of America', 'GE J47', '8/5/63'],\n",
       "    ['413.199', 'Tom Green', 'Wingfoot Express', 'WE J46', '10/2/64'],\n",
       "    ['434.22', 'Art Arfons', 'Green Monster', 'GE J79', '10/5/64'],\n",
       "    ['468.719', 'Craig Breedlove', 'Spirit of America', 'GE J79', '10/13/64'],\n",
       "    ['526.277', 'Craig Breedlove', 'Spirit of America', 'GE J79', '10/15/65'],\n",
       "    ['536.712', 'Art Arfons', 'Green Monster', 'GE J79', '10/27/65'],\n",
       "    ['555.127',\n",
       "     'Craig Breedlove',\n",
       "     'Spirit of America, Sonic 1',\n",
       "     'GE J79',\n",
       "     '11/2/65'],\n",
       "    ['576.553', 'Art Arfons', 'Green Monster', 'GE J79', '11/7/65'],\n",
       "    ['600.601',\n",
       "     'Craig Breedlove',\n",
       "     'Spirit of America, Sonic 1',\n",
       "     'GE J79',\n",
       "     '11/15/65'],\n",
       "    ['622.407', 'Gary Gabelich', 'Blue Flame', 'Rocket', '10/23/70'],\n",
       "    ['633.468', 'Richard Noble', 'Thrust 2', 'RR RG 146', '10/4/83'],\n",
       "    ['763.035', 'Andy Green', 'Thrust SSC', 'RR Spey', '10/15/97']],\n",
       "   [['Time (drops of water)', 'Distance (cm)'],\n",
       "    ['1', '10,11,9'],\n",
       "    ['2', '29, 31, 30'],\n",
       "    ['3', '59, 58, 61'],\n",
       "    ['4', '102, 100, 98'],\n",
       "    ['5', '122, 125, 127']]]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca43a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def table_to_text(table):\n",
    "    rows_text = []\n",
    "    for row in table:\n",
    "        clean_cells = [cell if cell is not None else '' for cell in row]\n",
    "        row_text = \"\\t\".join(clean_cells)\n",
    "        rows_text.append(row_text)\n",
    "    return \"\\n\".join(rows_text)\n",
    "\n",
    "def prepare_and_chunk_with_langchain(data, chunk_size=1000, chunk_overlap=100):\n",
    "    # Combine text + tables into one big string\n",
    "    combined_text = data['text']\n",
    "    for i, table in enumerate(data.get('tables', [])):\n",
    "        combined_text += f\"\\n\\n--- Table {i+1} ---\\n\"\n",
    "        combined_text += table_to_text(table)\n",
    "    print(\"combined\",combined_text)\n",
    "    # Create LangChain text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    # Split text into chunks (returns List[str])\n",
    "    chunks = text_splitter.split_text(combined_text)\n",
    "\n",
    "    # Optional: convert chunks to LangChain Document objects (useful for vectorstore ingestion)\n",
    "    docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "581d9759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "����������� �������� �������\n",
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two: Learning to Make Data Tables\n",
      "..............................................................................................\n",
      "Sample Data for Data Tables\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and\n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here\n",
      "are the results.\n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\n",
      "Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\n",
      "repeating this experiment include using safety goggles or safety spectacles and avoiding\n",
      "short circuits.\n",
      "Number of Coils Number of Paperclips\n",
      "5 3, 5, 4\n",
      "10 7, 8, 6\n",
      "15 11, 10, 12\n",
      "20 15, 13, 14\n",
      "Example 3: pH of Substances (GR 5–10)\n",
      "The following are pH values of common household substances taken by three different\n",
      "teams using pH probes. Safety precautions in repeating this experiment include hooded\n",
      "ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\n",
      "ammonia, or strong acids with children.\n",
      "Lemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\n",
      "Orange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\n",
      "Tomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\n",
      "10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\n",
      "12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\n",
      "Lye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\n",
      "10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\n",
      "Cola 3.0, 2.5, 3.2\n",
      "Teaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\n",
      "with the data as given and one with the pH scale 0 to 14 with the substances’ average\n",
      "pH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\n",
      "the upper end) or create a pH graphic organizer.\n",
      "1\n",
      "\n",
      "--- Table 1 ---\n",
      "Number of Coils\tNumber of Paperclips\n",
      "5\t3, 5, 4\n",
      "10\t7, 8, 6\n",
      "15\t11, 10, 12\n",
      "20\t15, 13, 14\n",
      "combined Example 4: Automobile Land Speed Records (GR 5-10)\n",
      "In the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\n",
      "Paris, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\n",
      "(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\n",
      "frozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\n",
      "Eagle is trying to break a land speed record of 800 mph. The Federation International de\n",
      "L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from\n",
      "http://www.landspeed.com/lsrinfo.asp.)\n",
      "Speed (mph) Driver Car Engine Date\n",
      "407.447 Craig Breedlove Spirit of America GE J47 8/5/63\n",
      "413.199 Tom Green Wingfoot Express WE J46 10/2/64\n",
      "434.22 Art Arfons Green Monster GE J79 10/5/64\n",
      "468.719 Craig Breedlove Spirit of America GE J79 10/13/64\n",
      "526.277 Craig Breedlove Spirit of America GE J79 10/15/65\n",
      "536.712 Art Arfons Green Monster GE J79 10/27/65\n",
      "555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\n",
      "576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)\n",
      "The following data were collected using a car with a water clock set to release a drop in\n",
      "a unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\n",
      "run. Create a data table with an average distance column and an average velocity column,\n",
      "create an average distance-time graph, and draw the best-fit line or curve. Estimate the\n",
      "car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\n",
      "it going at a constant speed, accelerating, or decelerating? How do you know?\n",
      "Time (drops of water) Distance (cm)\n",
      "1 10,11,9\n",
      "2 29, 31, 30\n",
      "3 59, 58, 61\n",
      "4 102, 100, 98\n",
      "5 122, 125, 127\n",
      "© 2006 WGBH Educational Foundation. All rights reserved.\n",
      "2\n",
      "\n",
      "--- Table 1 ---\n",
      "Speed (mph)\tDriver\tCar\tEngine Date\t\n",
      "407.447\tCraig Breedlove\tSpirit of America\tGE J47\t8/5/63\n",
      "413.199\tTom Green\tWingfoot Express\tWE J46\t10/2/64\n",
      "434.22\tArt Arfons\tGreen Monster\tGE J79\t10/5/64\n",
      "468.719\tCraig Breedlove\tSpirit of America\tGE J79\t10/13/64\n",
      "526.277\tCraig Breedlove\tSpirit of America\tGE J79\t10/15/65\n",
      "536.712\tArt Arfons\tGreen Monster\tGE J79\t10/27/65\n",
      "555.127\tCraig Breedlove\tSpirit of America, Sonic 1\tGE J79\t11/2/65\n",
      "576.553\tArt Arfons\tGreen Monster\tGE J79\t11/7/65\n",
      "600.601\tCraig Breedlove\tSpirit of America, Sonic 1\tGE J79\t11/15/65\n",
      "622.407\tGary Gabelich\tBlue Flame\tRocket\t10/23/70\n",
      "633.468\tRichard Noble\tThrust 2\tRR RG 146\t10/4/83\n",
      "763.035\tAndy Green\tThrust SSC\tRR Spey\t10/15/97\n",
      "\n",
      "--- Table 2 ---\n",
      "Time (drops of water)\tDistance (cm)\n",
      "1\t10,11,9\n",
      "2\t29, 31, 30\n",
      "3\t59, 58, 61\n",
      "4\t102, 100, 98\n",
      "5\t122, 125, 127\n"
     ]
    }
   ],
   "source": [
    "# Prepare and chunk\n",
    "final_docs = []\n",
    "for i, info in data.items():\n",
    "    documents = prepare_and_chunk_with_langchain(info)\n",
    "    final_docs.extend(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a7d7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'),\n",
       " Document(metadata={}, page_content='a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach'),\n",
       " Document(metadata={}, page_content='10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1'),\n",
       " Document(metadata={}, page_content='--- Table 1 ---\\nNumber of Coils\\tNumber of Paperclips\\n5\\t3, 5, 4\\n10\\t7, 8, 6\\n15\\t11, 10, 12\\n20\\t15, 13, 14'),\n",
       " Document(metadata={}, page_content='Example 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65'),\n",
       " Document(metadata={}, page_content='526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is'),\n",
       " Document(metadata={}, page_content='car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2'),\n",
       " Document(metadata={}, page_content='--- Table 1 ---\\nSpeed (mph)\\tDriver\\tCar\\tEngine Date\\t\\n407.447\\tCraig Breedlove\\tSpirit of America\\tGE J47\\t8/5/63\\n413.199\\tTom Green\\tWingfoot Express\\tWE J46\\t10/2/64\\n434.22\\tArt Arfons\\tGreen Monster\\tGE J79\\t10/5/64\\n468.719\\tCraig Breedlove\\tSpirit of America\\tGE J79\\t10/13/64\\n526.277\\tCraig Breedlove\\tSpirit of America\\tGE J79\\t10/15/65\\n536.712\\tArt Arfons\\tGreen Monster\\tGE J79\\t10/27/65\\n555.127\\tCraig Breedlove\\tSpirit of America, Sonic 1\\tGE J79\\t11/2/65\\n576.553\\tArt Arfons\\tGreen Monster\\tGE J79\\t11/7/65\\n600.601\\tCraig Breedlove\\tSpirit of America, Sonic 1\\tGE J79\\t11/15/65\\n622.407\\tGary Gabelich\\tBlue Flame\\tRocket\\t10/23/70\\n633.468\\tRichard Noble\\tThrust 2\\tRR RG 146\\t10/4/83\\n763.035\\tAndy Green\\tThrust SSC\\tRR Spey\\t10/15/97\\n\\n--- Table 2 ---\\nTime (drops of water)\\tDistance (cm)\\n1\\t10,11,9\\n2\\t29, 31, 30\\n3\\t59, 58, 61\\n4\\t102, 100, 98\\n5\\t122, 125, 127')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eab9633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 6\n",
      "sum_chunk_total_chars 5759\n",
      "Warning: Replace 'YOUR_OPENAI_API_KEY' with your actual key or set the OPENAI_API_KEY environment variable.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
    "chunks = text_splitter.split_text(full_text)\n",
    "sum_chunk_total_chars = 0\n",
    "for chunk in chunks:\n",
    "    #print(len(chunk))\n",
    "    sum_chunk_total_chars +=len(chunk)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "print(\"sum_chunk_total_chars\",sum_chunk_total_chars)\n",
    "# --- Step 2: Embedding ---\n",
    "# Ensure 'YOUR_OPENAI_API_KEY' is replaced with an actual valid key or an environment variable\n",
    "openai_api_key = OPENAI_KEY# Use environment variable or replace\n",
    "if openai_api_key == OPENAI_KEY:\n",
    "    print(\"Warning: Replace 'YOUR_OPENAI_API_KEY' with your actual key or set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=openai_api_key,disallowed_special=()) # Use the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7edebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Connect to Milvus and Store Data ---\n",
    "# Helper to create Milvus index\n",
    "def store_milvus(chunks, index_name, metric_type, index_type):\n",
    "    if utility.has_collection(index_name):\n",
    "        utility.drop_collection(index_name)\n",
    "    # Ensure the chunks are not empty before creating the collection\n",
    "    if not chunks:\n",
    "        print(f\"Warning: No chunks to store for index '{index_name}'. Skipping collection creation.\")\n",
    "        return None\n",
    "\n",
    "    return Milvus.from_texts(\n",
    "        chunks,\n",
    "        embedding=embeddings,\n",
    "        collection_name=index_name,\n",
    "        connection_args={\"uri\": \"https://in03-c8ed7ba112ba348.serverless.gcp-us-west1.cloud.zilliz.com\",\n",
    "        \"token\": MILVUS_API_TOKEN},\n",
    "        index_params={\"metric_type\": metric_type, \"index_type\": index_type})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3f01c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. deprecated:: 0.2.0 Use ``:class:`~langchain_milvus.MilvusVectorStore``` instead. It will not be removed until langchain-community==1.0.\n",
      "\n",
      "`Milvus` vector store.\n",
      "\n",
      "You need to install `pymilvus` and run Milvus.\n",
      "\n",
      "See the following documentation for how to run a Milvus instance:\n",
      "https://milvus.io/docs/install_standalone-docker.md\n",
      "\n",
      "If looking for a hosted Milvus, take a look at this documentation:\n",
      "https://zilliz.com/cloud and make use of the Zilliz vectorstore found in\n",
      "this project.\n",
      "\n",
      "IF USING L2/IP metric, IT IS HIGHLY SUGGESTED TO NORMALIZE YOUR DATA.\n",
      "\n",
      "Args:\n",
      "    embedding_function (Embeddings): Function used to embed the text.\n",
      "    collection_name (str): Which Milvus collection to use. Defaults to\n",
      "        \"LangChainCollection\".\n",
      "    collection_description (str): The description of the collection. Defaults to\n",
      "        \"\".\n",
      "    collection_properties (Optional[dict[str, any]]): The collection properties.\n",
      "        Defaults to None.\n",
      "        If set, will override collection existing properties.\n",
      "        For example: {\"collection.ttl.seconds\": 60}.\n",
      "    connection_args (Optional[dict[str, any]]): The connection args used for\n",
      "        this class comes in the form of a dict.\n",
      "    consistency_level (str): The consistency level to use for a collection.\n",
      "        Defaults to \"Session\".\n",
      "    index_params (Optional[dict]): Which index params to use. Defaults to\n",
      "        HNSW/AUTOINDEX depending on service.\n",
      "    search_params (Optional[dict]): Which search params to use. Defaults to\n",
      "        default of index.\n",
      "    drop_old (Optional[bool]): Whether to drop the current collection. Defaults\n",
      "        to False.\n",
      "    auto_id (bool): Whether to enable auto id for primary key. Defaults to False.\n",
      "        If False, you needs to provide text ids (string less than 65535 bytes).\n",
      "        If True, Milvus will generate unique integers as primary keys.\n",
      "    primary_field (str): Name of the primary key field. Defaults to \"pk\".\n",
      "    text_field (str): Name of the text field. Defaults to \"text\".\n",
      "    vector_field (str): Name of the vector field. Defaults to \"vector\".\n",
      "    metadata_field (str): Name of the metadata field. Defaults to None.\n",
      "        When metadata_field is specified,\n",
      "        the document's metadata will store as json.\n",
      "\n",
      "The connection args used for this class comes in the form of a dict,\n",
      "here are a few of the options:\n",
      "    address (str): The actual address of Milvus\n",
      "        instance. Example address: \"localhost:19530\"\n",
      "    uri (str): The uri of Milvus instance. Example uri:\n",
      "        \"http://randomwebsite:19530\",\n",
      "        \"tcp:foobarsite:19530\",\n",
      "        \"https://ok.s3.south.com:19530\".\n",
      "    host (str): The host of Milvus instance. Default at \"localhost\",\n",
      "        PyMilvus will fill in the default host if only port is provided.\n",
      "    port (str/int): The port of Milvus instance. Default at 19530, PyMilvus\n",
      "        will fill in the default port if only host is provided.\n",
      "    user (str): Use which user to connect to Milvus instance. If user and\n",
      "        password are provided, we will add related header in every RPC call.\n",
      "    password (str): Required when user is provided. The password\n",
      "        corresponding to the user.\n",
      "    secure (bool): Default is false. If set to true, tls will be enabled.\n",
      "    client_key_path (str): If use tls two-way authentication, need to\n",
      "        write the client.key path.\n",
      "    client_pem_path (str): If use tls two-way authentication, need to\n",
      "        write the client.pem path.\n",
      "    ca_pem_path (str): If use tls two-way authentication, need to write\n",
      "        the ca.pem path.\n",
      "    server_pem_path (str): If use tls one-way authentication, need to\n",
      "        write the server.pem path.\n",
      "    server_name (str): If use tls, need to write the common name.\n",
      "\n",
      "Example:\n",
      "    .. code-block:: python\n",
      "\n",
      "    from langchain_community.vectorstores import Milvus\n",
      "    from langchain_community.embeddings import OpenAIEmbeddings\n",
      "\n",
      "    embedding = OpenAIEmbeddings()\n",
      "    # Connect to a milvus instance on localhost\n",
      "    milvus_store = Milvus(\n",
      "        embedding_function = Embeddings,\n",
      "        collection_name = \"LangChainCollection\",\n",
      "        drop_old = True,\n",
      "        auto_id = True\n",
      "    )\n",
      "\n",
      "Raises:\n",
      "    ValueError: If the pymilvus python package is not installed.\n"
     ]
    }
   ],
   "source": [
    "print(Milvus.__doc__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e206c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Existing collections: ['genai_collection', 'flat_index', 'hnsw_index_image', 'hnsw_index', 'ivf_index']\n",
      "Type of server: Zilliz Cloud Vector Database(Compatible with Milvus 2.4)\n",
      "Connected to Milvus\n"
     ]
    }
   ],
   "source": [
    "milvus_flat = None # Initialize vectorstore variables\n",
    "milvus_hnsw = None\n",
    "milvus_ivf = None\n",
    "milvus_connected = False # Flag to indicate if Milvus connection was successful\n",
    "\n",
    "# Ensure Milvus server is running and accessible at localhost:19530\n",
    "try:\n",
    "    #connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "    # Connect to Zilliz cloud using endpoint URI and API key TOKEN.\n",
    "    #CLUSTER_ENDPOINT=\"https://in03-xxxx.api.gcp-us-west1.zillizcloud.com:443\"\n",
    "    #CLUSTER_ENDPOINT=\"https://in03-8bc9fd463236b1a.api.gcp-us-west1.zillizcloud.com:443\"\n",
    "    CLUSTER_ENDPOINT = \"https://in03-c8ed7ba112ba348.serverless.gcp-us-west1.cloud.zilliz.com\"\n",
    "\n",
    "    connections.connect(\n",
    "    alias='default',\n",
    "    uri=CLUSTER_ENDPOINT,\n",
    "    token=MILVUS_API_TOKEN\n",
    "\n",
    "    )\n",
    "    print(\"Connected. Existing collections:\", utility.list_collections())\n",
    "\n",
    "    # Check if the server is ready and get collection name.\n",
    "    print(f\"Type of server: {utility.get_server_version()}\")\n",
    "    print(\"Connected to Milvus\")\n",
    "    milvus_connected = True # Set flag to True on successful connection\n",
    "\n",
    "    # Create three indexes ONLY if co\n",
    "    # Create three indexes ONLY if connection is successful\n",
    "    #milvus_flat = store_milvus(chunks,\"flat_index\", \"L2\", IndexType.FLAT)\n",
    "    milvus_hnsw = store_milvus(chunks, \"hnsw_index\", \"COSINE\", \"HNSW\")\n",
    "    milvus_ivf = store_milvus(chunks, \"ivf_index\", \"COSINE\", \"IVF_FLAT\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Milvus or storing data: {e}\")\n",
    "    # The vectorstore variables will remain None if connection fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bb9e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Retriever + Timer + Accuracy ---\n",
    "def test_retriever(name, vectorstore, query):\n",
    "    if vectorstore is None: # Handle cases where collection wasn't created\n",
    "        print(f\"Skipping {name} retriever test as the collection was not created.\")\n",
    "        return []\n",
    "\n",
    "    # Use search_type argument for different retriever types\n",
    "    # Ensure the vectorstore object has the as_retriever method\n",
    "    if hasattr(vectorstore, 'as_retriever'):\n",
    "        if name == \"MMR\":\n",
    "            retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.5})\n",
    "        else:\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "        start = time.time()\n",
    "        # Ensure retriever returns list of Documents; handle potential errors\n",
    "        try:\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during {name} retrieval: {e}\")\n",
    "            docs = []\n",
    "            return docs\n",
    "\n",
    "        end = time.time()\n",
    "        print(f\"{name} Retriever Time: {end - start:.4f}s\")\n",
    "        # Calculate accuracy if docs are not empty\n",
    "        # Note: Simple substring match for accuracy is basic;\n",
    "        # more sophisticated methods are needed for robust evaluation.\n",
    "        if docs:\n",
    "            # Ensure document objects have 'page_content' attribute\n",
    "            hits = sum(1 for d in docs if hasattr(d, 'page_content') and query.lower() in d.page_content.lower())\n",
    "            accuracy = hits / len(docs)\n",
    "            print(f\"{name} Accuracy: {accuracy:.2%}\")\n",
    "        else:\n",
    "             print(f\"{name} Accuracy: N/A (no documents retrieved)\")\n",
    "\n",
    "        return docs\n",
    "    else:\n",
    "        print(f\"Error: Vectorstore object for {name} does not have 'as_retriever' method.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccf8e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from docx import Document\n",
    "\n",
    "def run_prompt_tuning_pipeline(query, milvus_flat, milvus_hnsw, milvus_ivf, milvus_connected, openai_api_key):\n",
    "    docs_flat, docs_hnsw, docs_mmr = [], [], []\n",
    "    \n",
    "    if milvus_connected:\n",
    "        docs_flat = test_retriever(\"Flat\", milvus_flat, query)\n",
    "        docs_hnsw = test_retriever(\"HNSW\", milvus_hnsw, query)\n",
    "        print(\"hnsw Top Docs:\", docs_hnsw)\n",
    "        print(\"hnsw context\",docs_hnsw[1])\n",
    "        docs_mmr = test_retriever(\"MMR\", milvus_ivf, query)\n",
    "        print(\"MMR Top Docs:\", docs_mmr)\n",
    "        print(\"mmr ivf context\",docs_mmr[1])\n",
    "        print(\"Skipping retriever tests as Milvus connection failed.\")\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an AI assistant. Use the following retrieved context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2, api_key=openai_api_key)\n",
    "    output = \"Could not generate answer due to an error or Milvus connection failure.\"\n",
    "\n",
    "    if milvus_ivf is not None and milvus_connected:\n",
    "        try:\n",
    "            retriever = milvus_ivf.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5, \"lambda_mult\": 0.5})\n",
    "            chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type_kwargs={\"prompt\": prompt})\n",
    "            output = chain.run(query)\n",
    "            print(\"Answer:\\n\", output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error running RetrievalQA chain with MMR: {e}\")\n",
    "            output = f\"Could not generate answer due to an error: {e}\"\n",
    "    else:\n",
    "        print(\"Milvus IVF collection was not initialized or Milvus connection failed.\")\n",
    "        output = \"Could not create RetrievalQA chain because the Milvus IVF collection was not initialized or Milvus connection failed.\"\n",
    "\n",
    "    # Export to DOCX if successful\n",
    "    if not output.startswith(\"Could not\"):\n",
    "        try:\n",
    "            doc = Document()\n",
    "            doc.add_heading(\"LLM Answer\", level=1)\n",
    "            doc.add_paragraph(output)\n",
    "            doc.save(\"LLM_Answer_Output.docx\")\n",
    "            print(\"Output saved to LLM_Answer_Output.docx\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving output to DOCX: {e}\")\n",
    "    else:\n",
    "        print(\"DOCX file not saved due to an error in generating the answer.\")\n",
    "\n",
    "    return {\n",
    "        \"flat_docs\": docs_flat,\n",
    "        \"hnsw_docs\": docs_hnsw,\n",
    "        \"mmr_docs\": docs_mmr,\n",
    "        \"answer\": output\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8976d8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Flat retriever test as the collection was not created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\108715618.py:18: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW Retriever Time: 0.9961s\n",
      "HNSW Accuracy: 0.00%\n",
      "hnsw Top Docs: [Document(metadata={'pk': 458312173147910713}, page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)'), Document(metadata={'pk': 458312173147910714}, page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2'), Document(metadata={'pk': 458312173147910712}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910709}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910710}, page_content='Ferret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;')]\n",
      "hnsw context page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)\n",
      "The following data were collected using a car with a water clock set to release a drop in\n",
      "a unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\n",
      "run. Create a data table with an average distance column and an average velocity column,\n",
      "create an average distance-time graph, and draw the best-fit line or curve. Estimate the\n",
      "car’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\n",
      "it going at a constant speed, accelerating, or decelerating? How do you know?\n",
      "Time (drops of water) Distance (cm)\n",
      "1 10,11,9\n",
      "2 29, 31, 30\n",
      "3 59, 58, 61\n",
      "4 102, 100, 98\n",
      "5 122, 125, 127\n",
      "© 2006 WGBH Educational Foundation. All rights reserved.\n",
      "2' metadata={'pk': 458312173147910714}\n",
      "MMR Retriever Time: 1.7273s\n",
      "MMR Accuracy: 0.00%\n",
      "MMR Top Docs: [Document(metadata={'pk': 458312173147910724}, page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)'), Document(metadata={'pk': 458312173147910720}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910722}, page_content='ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1'), Document(metadata={'pk': 458312173147910723}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910725}, page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2')]\n",
      "mmr ivf context page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "����������� �������� �������\n",
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two: Learning to Make Data Tables\n",
      "..............................................................................................\n",
      "Sample Data for Data Tables\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and\n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here\n",
      "are the results.\n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\n",
      "Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in' metadata={'pk': 458312173147910720}\n",
      "Skipping retriever tests as Milvus connection failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\515078519.py:29: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2, api_key=openai_api_key)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8188\\515078519.py:36: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  output = chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " The GE J47 is a turbojet engine developed by General Electric. It was one of the most widely produced jet engines in the United States and was used in several military aircraft during the 1950s and 1960s. The engine was known for its reliability and performance, contributing to its extensive use in various aircraft models. The J47 was also used in land speed record attempts, such as the one by Craig Breedlove in the Spirit of America, where it helped achieve a speed of 407.447 mph on August 5, 1963.\n",
      "Output saved to LLM_Answer_Output.docx\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me information about ge j47?\"\n",
    "results = run_prompt_tuning_pipeline(\n",
    "    query=query,\n",
    "    milvus_flat=milvus_flat,\n",
    "    milvus_hnsw=milvus_hnsw,\n",
    "    milvus_ivf=milvus_ivf,\n",
    "    milvus_connected=milvus_connected,\n",
    "    openai_api_key=OPENAI_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8312e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def write_results_to_csv_df(results, query,filename=\"results_output.csv\"):\n",
    "    # Normalize list values for clean storage\n",
    "    formatted_results = {}\n",
    "\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, list):\n",
    "            # Convert list of items to a single string (join by separator)\n",
    "            formatted_results[key] = [\"\\n---\\n\".join(str(v) for v in value)]\n",
    "        else:\n",
    "            formatted_results[key] = [str(value)]  # Wrap in list to make it a row\n",
    "\n",
    "    # Create a DataFrame with one row and keys as columns\n",
    "    df = pd.DataFrame.from_dict(formatted_results)\n",
    "    df[\"query\"]=query\n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Results saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c2a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results_output_table_q1.csv\n"
     ]
    }
   ],
   "source": [
    "write_results_to_csv_df(results,query, filename=\"results_output_table_q1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Flat retriever test as the collection was not created.\n",
      "HNSW Retriever Time: 0.6683s\n",
      "HNSW Accuracy: 0.00%\n",
      "hnsw Top Docs: [Document(metadata={'pk': 458312173011974298}, page_content='specific approach, leading to “efficient multitask serving.”\\nPrompt design (prompt engineering):\\n• The focus is on designing a very specific input or prompt to guide the pre-trained model to\\nproduce the desired output.\\n• Like prompt tuning, the main model remains “frozen”.\\n• This method is about exploiting the vast knowledge and capabilities of the pre-trained model\\nby just crafting the right input. As mentioned earlier, we will cover prompt engineering in\\ndetail in Chapter 5.\\nIn prompt tuning and prompt design, original model weights remain frozen, whereas in model tuning\\nmodel parameters are updated:\\n62 Fine-Tuning – Building Domain-Specific LLM Applications\\nFigure 3.10 – Model tuning, prompt tuning, and prompt design\\nThe following figure demonstrates model tuning (full fine-tuning) on the left and prompt tuning on\\nthe right. Tuning a model for a specific task necessitates creating a task-specific version of the entire\\npre-trained model for each downstream task, and separate batches of data must be used for inference.\\nOn the other hand, prompt tuning only necessitates storing a small, task-specific prompt for each task,\\nallowing for mixed-task inference using the original pre-trained model. With a T5 “XXL” model, each\\ntuned version of the model necessitates 11 billion parameters. In comparison, our tuned prompts only\\nnecessitate 20,480 parameters for each task, which is a reduction of over five orders of magnitude,\\nassuming a prompt length of 5 tokens:\\nFigure 3.11 – Model tuning versus prompt tuning\\nTechniques for fine-tuning models 63\\nNow, let’s look at the benefits of prompt tuning compared to prompt engineering and model fine-tuning:\\n• Compared to model fine-tuning, prompt tuning does not require copies of the LLMs to be\\ncreated for every task, thus resulting in a reduction in storage space\\n• Compared to few-shot prompt engineering, prompt tuning is not restricted to context length\\nor a limited number of examples\\n• Instead of crafting the best manual prompt to generate the desired output, you can use\\nbackpropagation to automatically learn a new model\\n• Resilient to domain shift\\nThe research paper The Power of Scale for Parameter-Efficient Prompt Tuning from Google highlights\\nthe experiment (Figure 3.12) that was conducted on the T5 Transformer model. As per the evaluation,\\nprompt tuning on the T5 model matched the quality of model tuning (or fine-tuning) as size increases,\\nwhile enabling the reuse of a single frozen model for all tasks. This approach significantly outperforms\\nfew-shot prompt designs using GPT-3. SuperGLUE is a benchmark that’s designed to comprehensively\\nevaluate the performance of various natural language understanding models across a range of challenging\\nlanguage tasks. We will learn more about SuperGLUE in the upcoming sections of this chapter:\\nFigure 3.12 – Relationship between SuperGLUE Score and Model Parameters\\nFigure 3.12 shows the relationship between SuperGLUE Score and Model Parameters for different fine-'), Document(metadata={'pk': 458312173011974297}, page_content='location in the embedding vector space. Hence, they are also referred to as hard prompts. On the\\nother hand, soft prompts are not confined to fixed, discrete words in natural language and can assume\\nany value in the multi-dimensional embedding vector space. In the following figure, words such as\\n“jump,” “fox,” and others are hard prompts, whereas the unlabeled black-colored token is a soft prompt.\\nPrompt tuning process\\nIn prompt tuning, soft prompts, also known as virtual tokens, are concatenated with the prompts;\\nit’s left to a supervised training process to determine the optimal values. As shown in the following\\nfigure, these trainable soft tokens are prepended to an embedding vector representation – in this case,\\n“The student learns science:”\\nFigure 3.8 – Soft prompt concatenation\\nThe following figure provides a more detailed representation of the process. Vectors are attached to\\nthe beginning of each embedded input vector and fed into the model, the prediction is compared\\nto the target to calculate a loss, and the error is backpropagated to calculate gradients, but only the\\nnew learnable vectors are updated, keeping the core model frozen. In other words, we are searching\\nthe embedding space for the best representation of the prompt that the LLMs should accept. Even\\nthough we can’t easily understand soft prompts learned this way, they can help us figure out how to\\ndo a task using the labeled dataset, doing the same job as text prompts written by hand but without\\nbeing limited to specific words or phrases:\\nFigure 3.9 – Prompt tuning process (detailed)\\nTechniques for fine-tuning models 61\\nNext, we’ll compare three methods: model tuning (full fine-tuning), prompt tuning, and prompt design\\n(prompt engineering). As shown in Figure 3.10, research conducted by Google shows the difference\\nbetween model tuning, prompt tuning, and prompt design (Guiding Frozen Language Models with\\nLearned Soft Prompts, QUINTA-FEIRA, FEVEREIRO 10, 2022, posted by Brian Lester, AI Resident,\\nand Noah Constant, Senior Staff Software Engineer, Google Research).\\nModel tuning (full fine-tuning):\\n• This method starts with a pre-trained model that is then further trained (or “tuned”) on a\\nspecific task using additional input data. The model becomes more specialized in this process.\\n• This method represents “strong task performance” as the model gets more aligned with the\\nparticular task.\\nPrompt tuning:\\n• Instead of tuning the entire model, only the prompt or input to the model is adjusted. The main\\nmodel remains “frozen” or unchanged.\\n• This introduces the concept of “tunable soft prompts,” which can be adjusted to get desired\\noutputs from the model.\\n• This method combines the general capabilities of the pre-trained model with a more task-\\nspecific approach, leading to “efficient multitask serving.”\\nPrompt design (prompt engineering):\\n• The focus is on designing a very specific input or prompt to guide the pre-trained model to\\nproduce the desired output.'), Document(metadata={'pk': 458312173011974296}, page_content='factors among these methods. PEFT techniques can be broadly classified into three categories:\\n• Selective\\n• Additive\\n• Reparameterization\\nThe following figure shows 30 PEFT methods that were discussed in 40 research papers published\\nbetween February 2019 and February 2023:\\nFigure 3.6 – PEFT methods that were discussed in research papers published between 2019 and 2023\\nThis diagram was taken from a survey published in the paper Scale Down to Scale Up: A Guide to\\nParameter-Efficient Tuning.\\nWe will dive into each of these categories in this section but only cover the most important PEFT\\ntechniques that have shown promising results.\\nTechniques for fine-tuning models 59\\nAdditive\\nThe core concept of additive methods involves fine-tuning a model by adding extra parameters or\\nlayers, exclusively training these new parameters, and keeping the original model weights frozen.\\nAlthough these techniques introduce new parameters to the network, they effectively reduce training\\ntimes and increase memory efficiency by decreasing the size of gradients and the optimizer states. This\\nis the most widely explored category of PEFT methods. A prominent method under this category is\\nprompt tuning with soft prompts.\\nPrompt tuning with soft prompts\\nThis type of tuning involves freezing the model weights and updating the prompt parameters instead\\nof model parameters like in model fine-tuning. When you freeze the weights of a model, you prevent\\nthem from being updated during training. These weights remain the same throughout the fine-\\ntuning process. It is a very compute and energy-efficient technique compared to traditional fine-\\ntuning. Prompt tuning should not be confused with prompt engineering, which we will discuss in\\nChapter 5. To understand prompt tuning better, we need to understand the concept of soft prompts\\nand embedding space.\\nSoft prompts and embedding space\\nAn embedding vector space is a high-dimensional space where words, phrases, or other types of data\\nare represented as vectors such that semantically similar items are located close to each other in the\\nspace. In the context of natural language processing, these embeddings capture semantic meanings\\nand relationships between words or sentences, allowing for operations that can infer similarities,\\nanalogies, and other linguistic patterns.\\nFigure 3.7 – Soft prompts versus hard prompts\\n60 Fine-Tuning – Building Domain-Specific LLM Applications\\nThe above figure depicts a 3D embedding vector space along the X, Y, and Z axes. Representing natural\\nlanguage through tokens is considered to be challenging because each token is associated with a specific\\nlocation in the embedding vector space. Hence, they are also referred to as hard prompts. On the\\nother hand, soft prompts are not confined to fixed, discrete words in natural language and can assume\\nany value in the multi-dimensional embedding vector space. In the following figure, words such as'), Document(metadata={'pk': 458312173011974308}, page_content='In the beginning, GPT-3 models weren’t originally designed to adhere to user instructions. Their\\ntraining focused on predicting the next word based on vast amounts of internet text data. Therefore,\\nthese models underwent fine-tuning using instructional datasets along with RLHF to enhance their\\nability to generate more useful and relevant responses aligned with human values when prompted\\nwith user instructions:\\nFigure 3.20 – The fine-tuning process with RLHF\\nThis figure depicts a schematic representation showcasing the InstructGPT fine-tuning process: (1)\\ninitial supervised fine-tuning, (2) training the reward model, and (3) executing RL through PPO using\\nthis established reward model. The utilization of this data to train respective models is indicated by\\nthe presence of blue arrows. In step 2, boxes A-D are samples from models that get ranked by labelers.\\nThe following figure provides a comparison of the response quality of fine-tuned models with RLHF,\\nsupervised fine-tuned models, and general GPT models. The Y-axis consists of a Likert scale and\\n76 Fine-Tuning – Building Domain-Specific LLM Applications\\nshows quality ratings of model outputs on a 1–7 scale (Y-axis), for various model sizes (X-axis), on\\nprompts submitted to InstructGPT models via the OpenAI API. The results reveal that InstructGPT\\noutputs receive significantly higher scores by labelers compared to outputs from GPT-3 models with\\nboth few-shot prompts and those without, as well as models that underwent supervised learning\\nfine-tuning. The labelers that were hired for this work were independent and were sourced from\\nScale AI and Upwork:\\nFigure 3.21 – Evaluation of InstructGPT (image credits: Open AI)\\nInstructGPT can be assessed across dimensions of toxicity, truthfulness, and appropriateness. Higher\\nscores are desirable for TruthfulQA and appropriateness, whereas lower scores are preferred for toxicity\\nand hallucinations. Measurement of hallucinations and appropriateness is conducted based on the\\ndistribution of prompts within our API. The outcomes are aggregated across various model sizes:\\nSummary 77\\nFigure 3.22 – Evaluation of InstructGPT\\nIn this section, we introduced the concept of fine-tuning and discussed a success stories of fine-tuning\\nwith RLHF that led to the development of InstructGPT.\\nSummary\\nFine-tuning is a powerful technique for customizing models, but it may not always be necessary. As\\nobserved, it can be time-consuming and may have initial upfront costs. It’s advisable to start with\\neasier and faster strategies, such as prompt engineering with few-shot examples, followed by data\\ngrounding using RAG. Only if the responses from the LLM remain suboptimal should you consider\\nfine-tuning. We will discuss RAG and prompt engineering in the following chapters.\\nIn this chapter, we delved into critical fine-tuning strategies tailored for specific tasks. Then, we\\nexplored an array of evaluation methods and benchmarks to assess your refined model. The RLHF'), Document(metadata={'pk': 458312173011974341}, page_content='Figure 5.11 – Taxonomy of prompt engineering techniques across multiple application domains\\nPrompt engineering best practices\\nIn the following list, we outline additional best practices to optimize and enhance your experience\\nwith prompt creation:\\n• Clarity and precision for accurate responses: Ensure that prompts are clear, concise, and\\nspecific, avoiding ambiguity or multiple interpretations:\\nBad Prompt Good Prompt\\nTell me about World War 1 How did World War 1 start, and who won it?\\nFigure 5.12 – Best practice: clarity and precision\\nTechniques for effective prompt engineering 121\\n• Descriptive: Be descriptive so that ChatGPT can understand your intent:\\nBad Prompt Good Prompt\\nWrite a poem about India. Write a poem about India focusing on its cultural diversity,\\ndeciduous cuisine, beautiful wildlife, nature, technology innovation,\\nand film industry.\\nFigure 5.13 – Best practice: be descriptive\\n• Format the output: Mention the format of the output, which can be bullet points, paragraphs,\\nsentences, tables, and languages, such as XML, HTML, and JSON. Use examples to articulate\\nthe desired output.\\n• Adjust the Temperature and Top_p parameters for creativity: As indicated in the parameters\\nsection, modifying the Temperatures and Top_p can significantly influence the variability of\\nthe model’s output. In scenarios that call for creativity and imagination, raising the temperature\\nproves beneficial. On the other hand, when dealing with legal applications that demand a\\nreduction in hallucinations, a lower temperature becomes advantageous.\\n• Use syntax as separators in prompts: In this example, for a more effective output, use “”” or\\n### to separate instruction and input data:\\nExample:\\nConvert the text below to Spanish\\nText: “””\\n{text input here}\\n“””\\n• Order of the prompt elements matter: It has been found, in certain instances, that giving an\\ninstruction before an example can improve the quality of your outputs. Additionally, the order\\nof examples can affect the output of prompts.\\n• Use guiding words: This helps steer the model toward a specific structure, such as the text\\nhighlighted in the following:\\nExample:\\n# Create a basic Python function that\\n# 1. Requests the user to enter a temperature in Celsius\\n# 2. Converts the Celsius temperature to Fahrenheit\\ndef ctf():\\n122 Effective Prompt Engineering Techniques: Unlocking Wisdom Through AI\\n• Instead of saying what not to provide, give alternative recommendations: Provide an alternative\\npath if ChatGPT is unable to perform a task, such as in the following highlighted message:\\nExample:\\nSystem Message: You are an AI nutrition consultant that provides nutrition consultation based\\non health and wellness goals of the customer Please note that any questions or inquiries beyond\\nthe scope of nutrition consultation will NOT be answered and instead will receive the response:\\n“Sorry! This question falls outside my domain of expertise!”\\nCustomer: How do I invest in 401K?')]\n",
      "hnsw context page_content='location in the embedding vector space. Hence, they are also referred to as hard prompts. On the\n",
      "other hand, soft prompts are not confined to fixed, discrete words in natural language and can assume\n",
      "any value in the multi-dimensional embedding vector space. In the following figure, words such as\n",
      "“jump,” “fox,” and others are hard prompts, whereas the unlabeled black-colored token is a soft prompt.\n",
      "Prompt tuning process\n",
      "In prompt tuning, soft prompts, also known as virtual tokens, are concatenated with the prompts;\n",
      "it’s left to a supervised training process to determine the optimal values. As shown in the following\n",
      "figure, these trainable soft tokens are prepended to an embedding vector representation – in this case,\n",
      "“The student learns science:”\n",
      "Figure 3.8 – Soft prompt concatenation\n",
      "The following figure provides a more detailed representation of the process. Vectors are attached to\n",
      "the beginning of each embedded input vector and fed into the model, the prediction is compared\n",
      "to the target to calculate a loss, and the error is backpropagated to calculate gradients, but only the\n",
      "new learnable vectors are updated, keeping the core model frozen. In other words, we are searching\n",
      "the embedding space for the best representation of the prompt that the LLMs should accept. Even\n",
      "though we can’t easily understand soft prompts learned this way, they can help us figure out how to\n",
      "do a task using the labeled dataset, doing the same job as text prompts written by hand but without\n",
      "being limited to specific words or phrases:\n",
      "Figure 3.9 – Prompt tuning process (detailed)\n",
      "Techniques for fine-tuning models 61\n",
      "Next, we’ll compare three methods: model tuning (full fine-tuning), prompt tuning, and prompt design\n",
      "(prompt engineering). As shown in Figure 3.10, research conducted by Google shows the difference\n",
      "between model tuning, prompt tuning, and prompt design (Guiding Frozen Language Models with\n",
      "Learned Soft Prompts, QUINTA-FEIRA, FEVEREIRO 10, 2022, posted by Brian Lester, AI Resident,\n",
      "and Noah Constant, Senior Staff Software Engineer, Google Research).\n",
      "Model tuning (full fine-tuning):\n",
      "• This method starts with a pre-trained model that is then further trained (or “tuned”) on a\n",
      "specific task using additional input data. The model becomes more specialized in this process.\n",
      "• This method represents “strong task performance” as the model gets more aligned with the\n",
      "particular task.\n",
      "Prompt tuning:\n",
      "• Instead of tuning the entire model, only the prompt or input to the model is adjusted. The main\n",
      "model remains “frozen” or unchanged.\n",
      "• This introduces the concept of “tunable soft prompts,” which can be adjusted to get desired\n",
      "outputs from the model.\n",
      "• This method combines the general capabilities of the pre-trained model with a more task-\n",
      "specific approach, leading to “efficient multitask serving.”\n",
      "Prompt design (prompt engineering):\n",
      "• The focus is on designing a very specific input or prompt to guide the pre-trained model to\n",
      "produce the desired output.' metadata={'pk': 458312173011974297}\n",
      "MMR Retriever Time: 2.4575s\n",
      "MMR Accuracy: 0.00%\n",
      "MMR Top Docs: [Document(metadata={'pk': 458312173011767863}, page_content='specific approach, leading to “efficient multitask serving.”\\nPrompt design (prompt engineering):\\n• The focus is on designing a very specific input or prompt to guide the pre-trained model to\\nproduce the desired output.\\n• Like prompt tuning, the main model remains “frozen”.\\n• This method is about exploiting the vast knowledge and capabilities of the pre-trained model\\nby just crafting the right input. As mentioned earlier, we will cover prompt engineering in\\ndetail in Chapter 5.\\nIn prompt tuning and prompt design, original model weights remain frozen, whereas in model tuning\\nmodel parameters are updated:\\n62 Fine-Tuning – Building Domain-Specific LLM Applications\\nFigure 3.10 – Model tuning, prompt tuning, and prompt design\\nThe following figure demonstrates model tuning (full fine-tuning) on the left and prompt tuning on\\nthe right. Tuning a model for a specific task necessitates creating a task-specific version of the entire\\npre-trained model for each downstream task, and separate batches of data must be used for inference.\\nOn the other hand, prompt tuning only necessitates storing a small, task-specific prompt for each task,\\nallowing for mixed-task inference using the original pre-trained model. With a T5 “XXL” model, each\\ntuned version of the model necessitates 11 billion parameters. In comparison, our tuned prompts only\\nnecessitate 20,480 parameters for each task, which is a reduction of over five orders of magnitude,\\nassuming a prompt length of 5 tokens:\\nFigure 3.11 – Model tuning versus prompt tuning\\nTechniques for fine-tuning models 63\\nNow, let’s look at the benefits of prompt tuning compared to prompt engineering and model fine-tuning:\\n• Compared to model fine-tuning, prompt tuning does not require copies of the LLMs to be\\ncreated for every task, thus resulting in a reduction in storage space\\n• Compared to few-shot prompt engineering, prompt tuning is not restricted to context length\\nor a limited number of examples\\n• Instead of crafting the best manual prompt to generate the desired output, you can use\\nbackpropagation to automatically learn a new model\\n• Resilient to domain shift\\nThe research paper The Power of Scale for Parameter-Efficient Prompt Tuning from Google highlights\\nthe experiment (Figure 3.12) that was conducted on the T5 Transformer model. As per the evaluation,\\nprompt tuning on the T5 model matched the quality of model tuning (or fine-tuning) as size increases,\\nwhile enabling the reuse of a single frozen model for all tasks. This approach significantly outperforms\\nfew-shot prompt designs using GPT-3. SuperGLUE is a benchmark that’s designed to comprehensively\\nevaluate the performance of various natural language understanding models across a range of challenging\\nlanguage tasks. We will learn more about SuperGLUE in the upcoming sections of this chapter:\\nFigure 3.12 – Relationship between SuperGLUE Score and Model Parameters\\nFigure 3.12 shows the relationship between SuperGLUE Score and Model Parameters for different fine-'), Document(metadata={'pk': 458312173011767931}, page_content='with LLMs by testing and trying out different prompts and using advanced logic and control\\nflow to make effective prompts. With Prompt Flow, developers can make executable flows that\\nconnect LLMs, prompts, and Python tools through a clear, visualized graph.\\n• In the intermediate (middle) Evaluation and Refinement stage, you assess the prompts for\\nfactors such as usefulness, fairness, groundedness, and content safety. Here, you also establish\\nand measure prompt quality and effectiveness using standardized metrics. Prompt flow allows\\nyou to build prompt variants and assess and compare their results through large-scale testing,\\nusing pre-built and custom evaluations.\\n• At the final stage at the bottom of the image, in the Optimization and Production stage, you\\ncan track and optimize your prompts for security and performance. You will also need to\\ncollaborate with others to get feedback. Prompt Flow can assist by launching your flow as an\\nendpoint for real-time inference, test that endpoint with sample data, monitor telemetry for\\nlatency and continuously track performance against key evaluation metrics.\\nWhile the preceding image is a simplified view on how to approach Prompt Flow and understand\\nit, let’s look at Prompt Flow and trace the steps through its deployment within an organization. In\\nthe following informational graphic image, taken from the Microsoft public website, LLMOps with\\nPrompt Flow and GitHub (reference link at the end of this chapter), there is a graphical description\\nof Prompt Flow deployment activities.\\nThere are quite a few steps involved in Prompt Flow, and we will not go into too much detail here,\\nleaving you with a link to explore this further (there is both a link to the main Microsoft website for\\nadditional documentation and the GitHub site, which has a compelling hand-on exercise in which\\nyou can follow along and learn).\\nFigure 6.11 – A summary of the Prompt Flow CI/CD deployment sequence\\n154 Developing and Operationalizing LLM-based Apps: Exploring Dev Frameworks and LLMOps\\nAs you can tell from the robustness of the preceding image, Prompt Flow empowers you and your\\norganization to confidently develop, rigorously test, fine-tune, and deploy CI/CD flows, allowing for\\nthe creation of reliable and advanced generative AI solutions, aligned to LLMOps.\\nIn the preceding image, there are three main environments: PR, Dev and Prod. A PR environment,\\nor pull request, is a short-lived environment containing changes that require review before being\\nmerged into the Dev and/or Prod environments. Oftentimes, the PR environment is called a test\\nenvironment. You can get more detailed information on setting up PR and other environments at\\nReview pull requests in pre-production environments.\\nThere are a number of steps in LLMOps Prompt Flow deployment:\\n• The initialization stage is where the LLMOps data are prepared in a stage/test environment,\\nsuch as data preparation and the entire environment setup.'), Document(metadata={'pk': 458312173011767906}, page_content='Figure 5.11 – Taxonomy of prompt engineering techniques across multiple application domains\\nPrompt engineering best practices\\nIn the following list, we outline additional best practices to optimize and enhance your experience\\nwith prompt creation:\\n• Clarity and precision for accurate responses: Ensure that prompts are clear, concise, and\\nspecific, avoiding ambiguity or multiple interpretations:\\nBad Prompt Good Prompt\\nTell me about World War 1 How did World War 1 start, and who won it?\\nFigure 5.12 – Best practice: clarity and precision\\nTechniques for effective prompt engineering 121\\n• Descriptive: Be descriptive so that ChatGPT can understand your intent:\\nBad Prompt Good Prompt\\nWrite a poem about India. Write a poem about India focusing on its cultural diversity,\\ndeciduous cuisine, beautiful wildlife, nature, technology innovation,\\nand film industry.\\nFigure 5.13 – Best practice: be descriptive\\n• Format the output: Mention the format of the output, which can be bullet points, paragraphs,\\nsentences, tables, and languages, such as XML, HTML, and JSON. Use examples to articulate\\nthe desired output.\\n• Adjust the Temperature and Top_p parameters for creativity: As indicated in the parameters\\nsection, modifying the Temperatures and Top_p can significantly influence the variability of\\nthe model’s output. In scenarios that call for creativity and imagination, raising the temperature\\nproves beneficial. On the other hand, when dealing with legal applications that demand a\\nreduction in hallucinations, a lower temperature becomes advantageous.\\n• Use syntax as separators in prompts: In this example, for a more effective output, use “”” or\\n### to separate instruction and input data:\\nExample:\\nConvert the text below to Spanish\\nText: “””\\n{text input here}\\n“””\\n• Order of the prompt elements matter: It has been found, in certain instances, that giving an\\ninstruction before an example can improve the quality of your outputs. Additionally, the order\\nof examples can affect the output of prompts.\\n• Use guiding words: This helps steer the model toward a specific structure, such as the text\\nhighlighted in the following:\\nExample:\\n# Create a basic Python function that\\n# 1. Requests the user to enter a temperature in Celsius\\n# 2. Converts the Celsius temperature to Fahrenheit\\ndef ctf():\\n122 Effective Prompt Engineering Techniques: Unlocking Wisdom Through AI\\n• Instead of saying what not to provide, give alternative recommendations: Provide an alternative\\npath if ChatGPT is unable to perform a task, such as in the following highlighted message:\\nExample:\\nSystem Message: You are an AI nutrition consultant that provides nutrition consultation based\\non health and wellness goals of the customer Please note that any questions or inquiries beyond\\nthe scope of nutrition consultation will NOT be answered and instead will receive the response:\\n“Sorry! This question falls outside my domain of expertise!”\\nCustomer: How do I invest in 401K?'), Document(metadata={'pk': 458312173011767861}, page_content='factors among these methods. PEFT techniques can be broadly classified into three categories:\\n• Selective\\n• Additive\\n• Reparameterization\\nThe following figure shows 30 PEFT methods that were discussed in 40 research papers published\\nbetween February 2019 and February 2023:\\nFigure 3.6 – PEFT methods that were discussed in research papers published between 2019 and 2023\\nThis diagram was taken from a survey published in the paper Scale Down to Scale Up: A Guide to\\nParameter-Efficient Tuning.\\nWe will dive into each of these categories in this section but only cover the most important PEFT\\ntechniques that have shown promising results.\\nTechniques for fine-tuning models 59\\nAdditive\\nThe core concept of additive methods involves fine-tuning a model by adding extra parameters or\\nlayers, exclusively training these new parameters, and keeping the original model weights frozen.\\nAlthough these techniques introduce new parameters to the network, they effectively reduce training\\ntimes and increase memory efficiency by decreasing the size of gradients and the optimizer states. This\\nis the most widely explored category of PEFT methods. A prominent method under this category is\\nprompt tuning with soft prompts.\\nPrompt tuning with soft prompts\\nThis type of tuning involves freezing the model weights and updating the prompt parameters instead\\nof model parameters like in model fine-tuning. When you freeze the weights of a model, you prevent\\nthem from being updated during training. These weights remain the same throughout the fine-\\ntuning process. It is a very compute and energy-efficient technique compared to traditional fine-\\ntuning. Prompt tuning should not be confused with prompt engineering, which we will discuss in\\nChapter 5. To understand prompt tuning better, we need to understand the concept of soft prompts\\nand embedding space.\\nSoft prompts and embedding space\\nAn embedding vector space is a high-dimensional space where words, phrases, or other types of data\\nare represented as vectors such that semantically similar items are located close to each other in the\\nspace. In the context of natural language processing, these embeddings capture semantic meanings\\nand relationships between words or sentences, allowing for operations that can infer similarities,\\nanalogies, and other linguistic patterns.\\nFigure 3.7 – Soft prompts versus hard prompts\\n60 Fine-Tuning – Building Domain-Specific LLM Applications\\nThe above figure depicts a 3D embedding vector space along the X, Y, and Z axes. Representing natural\\nlanguage through tokens is considered to be challenging because each token is associated with a specific\\nlocation in the embedding vector space. Hence, they are also referred to as hard prompts. On the\\nother hand, soft prompts are not confined to fixed, discrete words in natural language and can assume\\nany value in the multi-dimensional embedding vector space. In the following figure, words such as'), Document(metadata={'pk': 458312173011767873}, page_content='In the beginning, GPT-3 models weren’t originally designed to adhere to user instructions. Their\\ntraining focused on predicting the next word based on vast amounts of internet text data. Therefore,\\nthese models underwent fine-tuning using instructional datasets along with RLHF to enhance their\\nability to generate more useful and relevant responses aligned with human values when prompted\\nwith user instructions:\\nFigure 3.20 – The fine-tuning process with RLHF\\nThis figure depicts a schematic representation showcasing the InstructGPT fine-tuning process: (1)\\ninitial supervised fine-tuning, (2) training the reward model, and (3) executing RL through PPO using\\nthis established reward model. The utilization of this data to train respective models is indicated by\\nthe presence of blue arrows. In step 2, boxes A-D are samples from models that get ranked by labelers.\\nThe following figure provides a comparison of the response quality of fine-tuned models with RLHF,\\nsupervised fine-tuned models, and general GPT models. The Y-axis consists of a Likert scale and\\n76 Fine-Tuning – Building Domain-Specific LLM Applications\\nshows quality ratings of model outputs on a 1–7 scale (Y-axis), for various model sizes (X-axis), on\\nprompts submitted to InstructGPT models via the OpenAI API. The results reveal that InstructGPT\\noutputs receive significantly higher scores by labelers compared to outputs from GPT-3 models with\\nboth few-shot prompts and those without, as well as models that underwent supervised learning\\nfine-tuning. The labelers that were hired for this work were independent and were sourced from\\nScale AI and Upwork:\\nFigure 3.21 – Evaluation of InstructGPT (image credits: Open AI)\\nInstructGPT can be assessed across dimensions of toxicity, truthfulness, and appropriateness. Higher\\nscores are desirable for TruthfulQA and appropriateness, whereas lower scores are preferred for toxicity\\nand hallucinations. Measurement of hallucinations and appropriateness is conducted based on the\\ndistribution of prompts within our API. The outcomes are aggregated across various model sizes:\\nSummary 77\\nFigure 3.22 – Evaluation of InstructGPT\\nIn this section, we introduced the concept of fine-tuning and discussed a success stories of fine-tuning\\nwith RLHF that led to the development of InstructGPT.\\nSummary\\nFine-tuning is a powerful technique for customizing models, but it may not always be necessary. As\\nobserved, it can be time-consuming and may have initial upfront costs. It’s advisable to start with\\neasier and faster strategies, such as prompt engineering with few-shot examples, followed by data\\ngrounding using RAG. Only if the responses from the LLM remain suboptimal should you consider\\nfine-tuning. We will discuss RAG and prompt engineering in the following chapters.\\nIn this chapter, we delved into critical fine-tuning strategies tailored for specific tasks. Then, we\\nexplored an array of evaluation methods and benchmarks to assess your refined model. The RLHF')]\n",
      "mmr ivf context page_content='with LLMs by testing and trying out different prompts and using advanced logic and control\n",
      "flow to make effective prompts. With Prompt Flow, developers can make executable flows that\n",
      "connect LLMs, prompts, and Python tools through a clear, visualized graph.\n",
      "• In the intermediate (middle) Evaluation and Refinement stage, you assess the prompts for\n",
      "factors such as usefulness, fairness, groundedness, and content safety. Here, you also establish\n",
      "and measure prompt quality and effectiveness using standardized metrics. Prompt flow allows\n",
      "you to build prompt variants and assess and compare their results through large-scale testing,\n",
      "using pre-built and custom evaluations.\n",
      "• At the final stage at the bottom of the image, in the Optimization and Production stage, you\n",
      "can track and optimize your prompts for security and performance. You will also need to\n",
      "collaborate with others to get feedback. Prompt Flow can assist by launching your flow as an\n",
      "endpoint for real-time inference, test that endpoint with sample data, monitor telemetry for\n",
      "latency and continuously track performance against key evaluation metrics.\n",
      "While the preceding image is a simplified view on how to approach Prompt Flow and understand\n",
      "it, let’s look at Prompt Flow and trace the steps through its deployment within an organization. In\n",
      "the following informational graphic image, taken from the Microsoft public website, LLMOps with\n",
      "Prompt Flow and GitHub (reference link at the end of this chapter), there is a graphical description\n",
      "of Prompt Flow deployment activities.\n",
      "There are quite a few steps involved in Prompt Flow, and we will not go into too much detail here,\n",
      "leaving you with a link to explore this further (there is both a link to the main Microsoft website for\n",
      "additional documentation and the GitHub site, which has a compelling hand-on exercise in which\n",
      "you can follow along and learn).\n",
      "Figure 6.11 – A summary of the Prompt Flow CI/CD deployment sequence\n",
      "154 Developing and Operationalizing LLM-based Apps: Exploring Dev Frameworks and LLMOps\n",
      "As you can tell from the robustness of the preceding image, Prompt Flow empowers you and your\n",
      "organization to confidently develop, rigorously test, fine-tune, and deploy CI/CD flows, allowing for\n",
      "the creation of reliable and advanced generative AI solutions, aligned to LLMOps.\n",
      "In the preceding image, there are three main environments: PR, Dev and Prod. A PR environment,\n",
      "or pull request, is a short-lived environment containing changes that require review before being\n",
      "merged into the Dev and/or Prod environments. Oftentimes, the PR environment is called a test\n",
      "environment. You can get more detailed information on setting up PR and other environments at\n",
      "Review pull requests in pre-production environments.\n",
      "There are a number of steps in LLMOps Prompt Flow deployment:\n",
      "• The initialization stage is where the LLMOps data are prepared in a stage/test environment,\n",
      "such as data preparation and the entire environment setup.' metadata={'pk': 458312173011767931}\n",
      "Skipping retriever tests as Milvus connection failed.\n",
      "Answer:\n",
      " Creating a detailed explanation of the prompt tuning process with 500 bullet points is quite extensive and may not be practical in this format. However, I can provide a comprehensive overview of the prompt tuning process using a more concise set of bullet points. Here's a detailed explanation:\n",
      "\n",
      "- **Definition of Prompt Tuning:**\n",
      "  - Involves adjusting prompts to guide a pre-trained model to produce desired outputs.\n",
      "  - The model's original weights remain unchanged (frozen).\n",
      "  - Focuses on updating prompt parameters instead of model parameters.\n",
      "\n",
      "- **Purpose and Benefits:**\n",
      "  - Efficiently leverages the vast knowledge of pre-trained models.\n",
      "  - Reduces computational resources compared to full model fine-tuning.\n",
      "  - Allows for task-specific adaptation without altering the core model.\n",
      "  - Supports mixed-task inference using a single model.\n",
      "\n",
      "- **Comparison with Other Methods:**\n",
      "  - **Model Tuning:**\n",
      "    - Requires creating a task-specific version of the entire model.\n",
      "    - Involves updating model parameters.\n",
      "    - Needs separate data batches for each task.\n",
      "  - **Prompt Engineering:**\n",
      "    - Involves manually crafting prompts.\n",
      "    - Limited by context length and number of examples.\n",
      "    - Does not involve backpropagation for learning.\n",
      "\n",
      "- **Process of Prompt Tuning:**\n",
      "  - **Initialization:**\n",
      "    - Start with a pre-trained language model.\n",
      "    - Define the task and desired output.\n",
      "  - **Prompt Design:**\n",
      "    - Create initial prompts that guide the model towards the task.\n",
      "    - Use soft prompts, which are continuous embeddings, instead of discrete tokens.\n",
      "  - **Training:**\n",
      "    - Freeze the model weights.\n",
      "    - Update only the prompt parameters using backpropagation.\n",
      "    - Optimize prompts to improve task performance.\n",
      "  - **Evaluation:**\n",
      "    - Test the tuned prompts on validation data.\n",
      "    - Assess performance using standardized metrics.\n",
      "  - **Iteration:**\n",
      "    - Refine prompts based on evaluation results.\n",
      "    - Repeat training and evaluation until desired performance is achieved.\n",
      "\n",
      "- **Technical Aspects:**\n",
      "  - **Soft Prompts:**\n",
      "    - Represented in an embedding vector space.\n",
      "    - Not confined to fixed words, allowing flexibility.\n",
      "  - **Embedding Space:**\n",
      "    - High-dimensional space where semantically similar items are close.\n",
      "    - Soft prompts can assume any value in this space.\n",
      "\n",
      "- **Advantages of Prompt Tuning:**\n",
      "  - **Parameter Efficiency:**\n",
      "    - Requires significantly fewer parameters than model tuning.\n",
      "  - **Storage Efficiency:**\n",
      "    - No need to store multiple copies of the model for different tasks.\n",
      "  - **Domain Adaptability:**\n",
      "    - Resilient to domain shifts.\n",
      "  - **Performance:**\n",
      "    - Can match the quality of model tuning as model size increases.\n",
      "\n",
      "- **Applications:**\n",
      "  - Suitable for tasks requiring domain-specific knowledge.\n",
      "  - Effective for scenarios where computational resources are limited.\n",
      "\n",
      "- **Challenges:**\n",
      "  - Designing effective initial prompts.\n",
      "  - Balancing prompt complexity with task requirements.\n",
      "\n",
      "This overview provides a comprehensive understanding of the prompt tuning process, highlighting its purpose, benefits, and technical aspects. If you need further details or specific examples, feel free to ask!\n",
      "Output saved to LLM_Answer_Output.docx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93541082",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Give me information about rocket?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4e82a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results_output_table_q2.csv\n"
     ]
    }
   ],
   "source": [
    "write_results_to_csv_df(results, query,filename=\"results_output_table_q2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "335481a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Flat retriever test as the collection was not created.\n",
      "HNSW Retriever Time: 1.0294s\n",
      "HNSW Accuracy: 0.00%\n",
      "hnsw Top Docs: [Document(metadata={'pk': 458312173147910714}, page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2'), Document(metadata={'pk': 458312173147910713}, page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)'), Document(metadata={'pk': 458312173147910709}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910712}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910710}, page_content='Ferret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;')]\n",
      "hnsw context page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from\n",
      "http://www.landspeed.com/lsrinfo.asp.)\n",
      "Speed (mph) Driver Car Engine Date\n",
      "407.447 Craig Breedlove Spirit of America GE J47 8/5/63\n",
      "413.199 Tom Green Wingfoot Express WE J46 10/2/64\n",
      "434.22 Art Arfons Green Monster GE J79 10/5/64\n",
      "468.719 Craig Breedlove Spirit of America GE J79 10/13/64\n",
      "526.277 Craig Breedlove Spirit of America GE J79 10/15/65\n",
      "536.712 Art Arfons Green Monster GE J79 10/27/65\n",
      "555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\n",
      "576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)' metadata={'pk': 458312173147910713}\n",
      "MMR Retriever Time: 1.4721s\n",
      "MMR Accuracy: 0.00%\n",
      "MMR Top Docs: [Document(metadata={'pk': 458312173147910725}, page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2'), Document(metadata={'pk': 458312173147910720}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910722}, page_content='ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1'), Document(metadata={'pk': 458312173147910723}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910724}, page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)')]\n",
      "mmr ivf context page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\n",
      "www.sedl.org/afterschool/toolkits\n",
      "����������� �������� �������\n",
      "Tutoring to Enhance Science Skills\n",
      "Tutoring Two: Learning to Make Data Tables\n",
      "..............................................................................................\n",
      "Sample Data for Data Tables\n",
      "Use these data to create data tables following the Guidelines for Making a Data Table and\n",
      "Checklist for a Data Table.\n",
      "Example 1: Pet Survey (GR 2–3)\n",
      "Ms. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\n",
      "School. Students were asked to select their favorite pet from a list of eight animals. Here\n",
      "are the results.\n",
      "Lizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\n",
      "Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in' metadata={'pk': 458312173147910720}\n",
      "Skipping retriever tests as Milvus connection failed.\n",
      "Answer:\n",
      " The context provided includes information about land speed records, some of which involve rocket-powered vehicles. Specifically, the record set by Gary Gabelich in the Blue Flame rocket car is relevant. Here are the details:\n",
      "\n",
      "- **Driver:** Gary Gabelich\n",
      "- **Vehicle:** Blue Flame\n",
      "- **Type:** Rocket-powered car\n",
      "- **Speed:** 622.407 mph\n",
      "- **Date:** October 23, 1970\n",
      "\n",
      "The Blue Flame was a rocket-powered vehicle that set a land speed record, showcasing the use of rocket propulsion in achieving high speeds on land.\n",
      "Output saved to LLM_Answer_Output.docx\n"
     ]
    }
   ],
   "source": [
    "results = run_prompt_tuning_pipeline(\n",
    "    query=query,\n",
    "    milvus_flat=milvus_flat,\n",
    "    milvus_hnsw=milvus_hnsw,\n",
    "    milvus_ivf=milvus_ivf,\n",
    "    milvus_connected=milvus_connected,\n",
    "    openai_api_key=OPENAI_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1ad346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Give me diffrent ph vlues used by students?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a49411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Flat retriever test as the collection was not created.\n",
      "HNSW Retriever Time: 0.8157s\n",
      "HNSW Accuracy: 0.00%\n",
      "hnsw Top Docs: [Document(metadata={'pk': 458312173147910711}, page_content='ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1'), Document(metadata={'pk': 458312173147910710}, page_content='Ferret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;'), Document(metadata={'pk': 458312173147910712}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910709}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910714}, page_content='576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)\\nThe following data were collected using a car with a water clock set to release a drop in\\na unit of time and a meter stick. The car rolled down an inclined plane. Three trials were\\nrun. Create a data table with an average distance column and an average velocity column,\\ncreate an average distance-time graph, and draw the best-fit line or curve. Estimate the\\ncar’s distance traveled and velocity at six drops of water. Describe the motion of the car. Is\\nit going at a constant speed, accelerating, or decelerating? How do you know?\\nTime (drops of water) Distance (cm)\\n1 10,11,9\\n2 29, 31, 30\\n3 59, 58, 61\\n4 102, 100, 98\\n5 122, 125, 127\\n© 2006 WGBH Educational Foundation. All rights reserved.\\n2')]\n",
      "hnsw context page_content='Ferret 10\n",
      "Example 2: Electromagnets—Increasing Coils (GR 3–5)\n",
      "The following data were collected using an electromagnet with a 1.5 volt battery, a switch,\n",
      "a piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\n",
      "repeating this experiment include using safety goggles or safety spectacles and avoiding\n",
      "short circuits.\n",
      "Number of Coils Number of Paperclips\n",
      "5 3, 5, 4\n",
      "10 7, 8, 6\n",
      "15 11, 10, 12\n",
      "20 15, 13, 14\n",
      "Example 3: pH of Substances (GR 5–10)\n",
      "The following are pH values of common household substances taken by three different\n",
      "teams using pH probes. Safety precautions in repeating this experiment include hooded\n",
      "ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\n",
      "ammonia, or strong acids with children.\n",
      "Lemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\n",
      "Orange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;' metadata={'pk': 458312173147910710}\n",
      "MMR Retriever Time: 1.3718s\n",
      "MMR Accuracy: 0.00%\n",
      "MMR Top Docs: [Document(metadata={'pk': 458312173147910722}, page_content='ventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;\\nTomatoes 4.5, 4.2, 4.0; Bottled water 6.7, 7.0, 7.2; Milk of magnesia 10.5, 10.3,\\n10.6; Liquid hand soap 9.0, 10.0, 9.5; Vinegar 2.2, 2.9, 3.0; Household bleach\\n12.5, 12.5, 12.7; Milk 6.6, 6.5, 6.4; Household ammonia 11.5, 11.0, 11.5;\\nLye 13.0, 13.5, 13.4; and Sodium hydroxide 14.0, 14.0, 13.9; Anti-freeze 10.1,\\n10.9, 9.7; Windex 9.9. 10.2, 9.5; Liquid detergent 10.5, 10.0, 10.3; and\\nCola 3.0, 2.5, 3.2\\nTeaching tip: The pH scale is from 0 to 14. Have students make two data tables, one\\nwith the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1'), Document(metadata={'pk': 458312173147910724}, page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date\\n407.447 Craig Breedlove Spirit of America GE J47 8/5/63\\n413.199 Tom Green Wingfoot Express WE J46 10/2/64\\n434.22 Art Arfons Green Monster GE J79 10/5/64\\n468.719 Craig Breedlove Spirit of America GE J79 10/13/64\\n526.277 Craig Breedlove Spirit of America GE J79 10/15/65\\n536.712 Art Arfons Green Monster GE J79 10/27/65\\n555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\\n576.553 Art Arfons Green Monster GE J79 11/7/65\\n600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\\n622.407 Gary Gabelich Blue Flame Rocket 10/23/70\\n633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\\n763.035 Andy Green Thrust SSC RR Spey 10/15/97\\nExample 5: Distance and Time (GR 8-10)'), Document(metadata={'pk': 458312173147910720}, page_content='NATIONAL PARTNERSHIP FOR QUALITY AFTERSCHOOL LEARNING\\nwww.sedl.org/afterschool/toolkits\\n����������� �������� �������\\nTutoring to Enhance Science Skills\\nTutoring Two: Learning to Make Data Tables\\n..............................................................................................\\nSample Data for Data Tables\\nUse these data to create data tables following the Guidelines for Making a Data Table and\\nChecklist for a Data Table.\\nExample 1: Pet Survey (GR 2–3)\\nMs. Hubert’s afterschool students took a survey of the 600 students at Morales Elementary\\nSchool. Students were asked to select their favorite pet from a list of eight animals. Here\\nare the results.\\nLizard 25, Dog 250, Cat 115, Bird 50, Guinea pig 30, Hamster 45, Fish 75,\\nFerret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in'), Document(metadata={'pk': 458312173147910723}, page_content='with the data as given and one with the pH scale 0 to 14 with the substances’ average\\npH in rank order on the scale (Battery acid at the lower end and Sodium hydroxide at\\nthe upper end) or create a pH graphic organizer.\\n1\\nExample 4: Automobile Land Speed Records (GR 5-10)\\nIn the first recorded automobile race in 1898, Count Gaston de Chasseloup-Laubat of\\nParis, France, drove 1 kilometer in 57 seconds for an average speed of 39.2 miles per hour\\n(mph) or 63.1 kilometers per hour (kph). In 1904, Henry Ford drove his Ford Arrow across\\nfrozen Lake St. Clair, MI, at an average speed of 91.4 mph. Now, the North American\\nEagle is trying to break a land speed record of 800 mph. The Federation International de\\nL’Automobile (FIA), the world’s governing body for motor sport and land speed records,\\nrecorded the following land speed records. (Retrieved on February 5, 2006, from\\nhttp://www.landspeed.com/lsrinfo.asp.)\\nSpeed (mph) Driver Car Engine Date'), Document(metadata={'pk': 458312173147910721}, page_content='Ferret 10\\nExample 2: Electromagnets—Increasing Coils (GR 3–5)\\nThe following data were collected using an electromagnet with a 1.5 volt battery, a switch,\\na piece of #20 insulated wire, and a nail. Three trials were run. Safety precautions in\\nrepeating this experiment include using safety goggles or safety spectacles and avoiding\\nshort circuits.\\nNumber of Coils Number of Paperclips\\n5 3, 5, 4\\n10 7, 8, 6\\n15 11, 10, 12\\n20 15, 13, 14\\nExample 3: pH of Substances (GR 5–10)\\nThe following are pH values of common household substances taken by three different\\nteams using pH probes. Safety precautions in repeating this experiment include hooded\\nventilation, chemical-splash safety goggles, gloves, and apron. Do not use bleach,\\nammonia, or strong acids with children.\\nLemon juice 2.4, 2.0, 2.2; Baking soda (1 Tbsp) in Water (1 cup) 8.4, 8.3, 8.7;\\nOrange juice 3.5, 4.0, 3.4; Battery acid 1.0, 0.7, 0.5; Apples 3.0, 3.2, 3.5;')]\n",
      "mmr ivf context page_content='L’Automobile (FIA), the world’s governing body for motor sport and land speed records,\n",
      "recorded the following land speed records. (Retrieved on February 5, 2006, from\n",
      "http://www.landspeed.com/lsrinfo.asp.)\n",
      "Speed (mph) Driver Car Engine Date\n",
      "407.447 Craig Breedlove Spirit of America GE J47 8/5/63\n",
      "413.199 Tom Green Wingfoot Express WE J46 10/2/64\n",
      "434.22 Art Arfons Green Monster GE J79 10/5/64\n",
      "468.719 Craig Breedlove Spirit of America GE J79 10/13/64\n",
      "526.277 Craig Breedlove Spirit of America GE J79 10/15/65\n",
      "536.712 Art Arfons Green Monster GE J79 10/27/65\n",
      "555.127 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/2/65\n",
      "576.553 Art Arfons Green Monster GE J79 11/7/65\n",
      "600.601 Craig Breedlove Spirit of America, Sonic 1 GE J79 11/15/65\n",
      "622.407 Gary Gabelich Blue Flame Rocket 10/23/70\n",
      "633.468 Richard Noble Thrust 2 RR RG 146 10/4/83\n",
      "763.035 Andy Green Thrust SSC RR Spey 10/15/97\n",
      "Example 5: Distance and Time (GR 8-10)' metadata={'pk': 458312173147910724}\n",
      "Skipping retriever tests as Milvus connection failed.\n",
      "Answer:\n",
      " The different pH values used by students, as mentioned in the context, are:\n",
      "\n",
      "- Lemon juice: 2.4, 2.0, 2.2\n",
      "- Baking soda (1 Tbsp) in Water (1 cup): 8.4, 8.3, 8.7\n",
      "- Orange juice: 3.5, 4.0, 3.4\n",
      "- Battery acid: 1.0, 0.7, 0.5\n",
      "- Apples: 3.0, 3.2, 3.5\n",
      "- Tomatoes: 4.5, 4.2, 4.0\n",
      "- Bottled water: 6.7, 7.0, 7.2\n",
      "- Milk of magnesia: 10.5, 10.3, 10.6\n",
      "- Liquid hand soap: 9.0, 10.0, 9.5\n",
      "- Vinegar: 2.2, 2.9, 3.0\n",
      "- Household bleach: 12.5, 12.5, 12.7\n",
      "- Milk: 6.6, 6.5, 6.4\n",
      "- Household ammonia: 11.5, 11.0, 11.5\n",
      "- Lye: 13.0, 13.5, 13.4\n",
      "- Sodium hydroxide: 14.0, 14.0, 13.9\n",
      "- Anti-freeze: 10.1, 10.9, 9.7\n",
      "- Windex: 9.9, 10.2, 9.5\n",
      "- Liquid detergent: 10.5, 10.0, 10.3\n",
      "- Cola: 3.0, 2.5, 3.2\n",
      "Output saved to LLM_Answer_Output.docx\n"
     ]
    }
   ],
   "source": [
    "results = run_prompt_tuning_pipeline(\n",
    "    query=query,\n",
    "    milvus_flat=milvus_flat,\n",
    "    milvus_hnsw=milvus_hnsw,\n",
    "    milvus_ivf=milvus_ivf,\n",
    "    milvus_connected=milvus_connected,\n",
    "    openai_api_key=OPENAI_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "386d3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to results_output_table_q6.csv\n"
     ]
    }
   ],
   "source": [
    "write_results_to_csv_df(results, query,filename=\"results_output_table_q6.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
